{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    " This notebook demonstrates how to build a rag pipeline using gemma, langchain and chromadb.\n",
    " \n",
    "1.[Introduction](#introduction)\n",
    "\n",
    "2.[Installation](#installation)\n",
    "\n",
    "3.[Importations](#importation)\n",
    "\n",
    "4.[Data](#data)<br>\n",
    "1. [Spliting the pdf into pages](#spliting_pages)<br>\n",
    "2. [Spliting the pages into chunks-Chunking](#chunking)\n",
    "\n",
    "5.[Building the Vector DataBase](#db)\n",
    "\n",
    "6.[Model](#model)\n",
    "\n",
    "7.[Retrieval](#retrieval)\n",
    "\n",
    "8.[Augmentation](#augmentation)\n",
    "\n",
    "9.[Query](#query)\n",
    "\n",
    "10.[Generation](#generation)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "<a id=\"installation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!pip install --upgrade jupyter #in case you face the issue in loading the model \n",
    "#!pip install --upgrade ipywidgets # // // // // // //\n",
    "#!pip install --upgrade tqdm # // // // // // //\n",
    "#!pip install bitsandbytes accelerate\n",
    "#!pip install tiktoken\n",
    "#!pip install pypdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations\n",
    "<a id=\"importation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pypdf import PdfReader\n",
    "import ipywidgets as widgets\n",
    "import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "<a id =\"data\"></a>\n",
    "For this pipiline we will use the institutional regulations of poyltech Angers.\n",
    "\n",
    "The data comes in a pdf format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting the pdf into pages \n",
    "<a id=\"spliting_pages\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Page 4 sur 17  \\n 1. PRÉAMBULE \\nLa formation d’ingénieur comporte 5 années d’études  post baccalauréat. Il débute par un parcours intégré de \\ndeux années appelé « Parcours des écoles d’ingénieu rs Polytech (PeiP) » et un cycle d’ingénieurs sur l es trois \\ndernières années. Le présent règlement concerne les  deux années de PeiP de Polytech Angers.   \\n \\nCe règlement des études est révisable chaque année et validé par le conseil d'école. \\n2. ORGANISATION DES ÉTUDES \\n2.1. RÉPARTITION TEMPORELLE ET UNITÉS D’ENSEIGNEMEN T \\nLe volume horaire total d’enseignement encadré est compris entre 1400 h et 1600 h, Les enseignements s ont \\norganisés en 4 semestres. \\nLes enseignements (matières, modules, éléments cons titutifs pédagogiques) sont groupés en Unités \\nd’Enseignement (UE) au sein de chaque semestre. Cha que UE assure une cohérence pédagogique entre \\ndiverses matières et contribue à l’acquisition de c ompétences identifiées. A chaque UE est associé un nombre \\nfixé de crédits ECTS. A chaque semestre sont associ és 30 ECTS définis dans la maquette pédagogique. \\n2.2. NATURE DES ENSEIGNEMENTS  \\nLa formation comprend : \\n• des enseignements sous forme de cours, travaux diri gés, travaux pratiques ; \\n• des travaux personnels tuteurés dans le cadre d’une  pédagogie de projets ; \\n• un stage et des visites d’entreprises ;   \\n• des conférences, séminaires ; \\n• des activités d’investissement personnel ou collect if agréées par l’école.  \\nLes maquettes pédagogiques (programmes, volumes hor aires, répartition en UE, pondération des \\névaluations au sein d’une même UE) sont publiées an nuellement pour chaque spécialité. Les modalités \\nd’évaluation sont fixées avant la fin du premier mo is d’enseignement de l’année universitaire et \\ncommuniquées aux élèves ingénieurs et aux enseignan ts dans le même délai. \\n \\n2.3. STAGES ET EXPÉRIENCES PROFESSIONNELLES \\nLes élèves de PeiP doivent réaliser une activité en  entreprise de quatre à huit semaines. Cela peut êt re un \\nstage de découverte ou une expérience professionnel le. Cette expérience devra être validée en amont \\npar le responsable PeiP et elle sera attestée par u n contrat de travail ou une convention de stage. \\nLes étudiants doivent remettre un mémoire présentan t leur activité. L'évaluation de cette activité ser a \\nassurée par le tuteur de l'école en charge du suivi  de l'étudiant en association, le cas échéant, avec  le \\nmaître de stage de l'entreprise d'accueil.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "pdf_reader = PdfReader(\"./data/Reglement_etudes_Polytech_Angers_2020-2021.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in pdf_reader.pages]\n",
    "pdf_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the texts into chunks \n",
    "<a id=\"chunking\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 35\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "#print(word_wrap(character_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the vector database -Chroma\n",
    "<a id=\"db\"></a>\n",
    "The vector database is responsible for storing and organizing the embeddings of the documents that our model will retrieve and use to generate responses.\n",
    "\n",
    "For embedding we will use the default embedding model provided by chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new chroma collection\n",
    "client = chromadb.Client()\n",
    "chroma_collection = client.get_or_create_collection(name=\"Reglement_etudes_Polytech_Angers\")\n",
    "ids = [str(i) for i in range(len(character_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=character_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Model\n",
    "<a id=\"model\"></a>\n",
    "For the model we will use the open source LLM provided by googel Gemma 7bit instruction (gemma-7b-it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using model: ./google/gemma-7b-it\n",
      "[INFO] Using attention type: sdpa\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7df8f6103d54b42a1b485587120f4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers.utils import is_flash_attn_2_available \n",
    "# 1. Specify the model to be used\n",
    "model_name = \"./google/gemma-7b-it\"\n",
    "print(f\"[INFO] Using model: {model_name}\")\n",
    "\n",
    "use_quantization = False\n",
    "\n",
    "# 2. (Optional) Create quantization configuration for smaller model loading\n",
    "# Requires additional library installation and NVIDIA GPU with compute capability of 8.0 or above\n",
    "from transformers import BitsAndBytesConfig\n",
    "if use_quantization:\n",
    "    from transformers import BitsAndBytesConfig\n",
    "    quantization_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "# 3. (Optional) Specify attention implementation for faster inference\n",
    "# Requires additional library installation and NVIDIA GPU with compute capability of 8.0 or above\n",
    "attn_type = \"flash_attention_2\" if is_flash_attn_2_available() and torch.cuda.get_device_capability(0)[0] >= 8 else \"sdpa\"\n",
    "print(f\"[INFO] Using attention type: {attn_type}\")\n",
    "\n",
    "# 4. Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 5. Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             quantization_config=quantization_config if use_quantization else None,\n",
    "                                             low_cpu_mem_usage=False, \n",
    "                                             attn_implementation=attn_type)\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# 6. (Optional) Move the model to GPU\n",
    "if not use_quantization:\n",
    "    model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaForCausalLM(\n",
      "  (model): GemmaModel(\n",
      "    (embed_tokens): Embedding(256000, 3072, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-27): 28 x GemmaDecoderLayer(\n",
      "        (self_attn): GemmaSdpaAttention(\n",
      "          (q_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
      "          (k_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
      "          (v_proj): Linear(in_features=3072, out_features=4096, bias=False)\n",
      "          (o_proj): Linear(in_features=4096, out_features=3072, bias=False)\n",
      "          (rotary_emb): GemmaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): GemmaMLP(\n",
      "          (gate_proj): Linear(in_features=3072, out_features=24576, bias=False)\n",
      "          (up_proj): Linear(in_features=3072, out_features=24576, bias=False)\n",
      "          (down_proj): Linear(in_features=24576, out_features=3072, bias=False)\n",
      "          (act_fn): GELUActivation()\n",
      "        )\n",
      "        (input_layernorm): GemmaRMSNorm()\n",
      "        (post_attention_layernorm): GemmaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): GemmaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=3072, out_features=256000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "<a id=\"retrieval\"></a>\n",
    "The `generate_context` represents our retrival , in our example we return the top 5 documents relevant to our query.\n",
    "\n",
    "The default distance used in chroma is the `cosine` distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context(query):\n",
    "    results = chroma_collection.query(\n",
    "    query_texts=[query],\n",
    "    n_results=5,\n",
    "    include=['documents']\n",
    "    )\n",
    "    \n",
    "    res = [{\"sentence_chunk\": str(item)} for item in results['documents'][0]]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation\n",
    "<a id=\"augmentation\"></id>\n",
    "In this step, we craft our prompt, where we define the model's role as a student assistant and incorporate the contextual elements provided by `generate_context` function so it provides  the language model with the necessary information to generate accurate and relevant responses given a query input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatter(query: str, \n",
    "                     context_items: list[dict]) -> str:\n",
    "    \"\"\"\n",
    "    Augments query with text-based context from context_items.\n",
    "    \"\"\"\n",
    "    # Join context items into one dotted paragraph\n",
    "    context = \"- \" + \"\\n- \".join([item[\"sentence_chunk\"] for item in context_items])\n",
    "\n",
    "\n",
    "    base_prompt = \"\"\"  Vous etes un assitant aux etudiants qui veulent se renseigner sur le reglement interieur de polytech Angers. \n",
    "    Essayez de repondre aux requetes d'utilisateur , si tu ne connais pas la reponse ne l'invente pas \n",
    "\\nMaintenant utiliser les elements de contexte suivant pour repondre a la requetes de l'utilisateur:\n",
    "{context}\n",
    "\\nRelevant passages: <extract relevant passages from the context here>\n",
    "User query: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    # Update base prompt with context items and query   \n",
    "    base_prompt = base_prompt.format(context=context, query=query)\n",
    "\n",
    "\n",
    "    # Create prompt template for instruction-tuned model\n",
    "    dialogue_template = [\n",
    "        {\"role\": \"user\",\n",
    "        \"content\": base_prompt}\n",
    "    ]\n",
    "     # Apply the chat template\n",
    "    prompt = tokenizer.apply_chat_template(conversation=dialogue_template,\n",
    "                                          tokenize=False,\n",
    "                                          add_generation_prompt=True)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query\n",
    "<a id=\"query\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"Quelle est la limite maximale d'absences justifiées pour un élève ?\"\n",
    "\n",
    "context = generate_context(query)\n",
    "\n",
    "prompt = prompt_formatter(query=query,\n",
    "                          context_items=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation: answer of the model \n",
    "<a id=\"generation\"></a>\n",
    "Finally we come to the last part \"Answer Generation\".\n",
    "\n",
    "We perform the following steps \n",
    "1. Tokenize the formatted prompt,\n",
    "2. Generate a response using the model, and\n",
    "3. Decode the output to present the final answer to the user's query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Quelle est la limite maximale d'absences justifiées pour un élève ?\n",
      "RAG answer:\n",
      "<bos>La limite maximale d'absences justifiées pour un élève est de 30% du volume horaire du semestre. Si l'absence d'un élève dépasse cette limite, le semestre ne peut pas être validé et l'élève peut être proposé de répéter son année à titre exceptionnel.<eos>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# Generate an output of tokens\n",
    "outputs = model.generate(**input_ids,\n",
    "                             #temperature=0.5, # lower temperature = more deterministic outputs, higher temperature = more creative outputs\n",
    "                             do_sample=False, # whether or not to use sampling, see https://huyenchip.com/2024/01/16/sampling.html for more\n",
    "                             max_new_tokens=1024) # how many new tokens to generate from prompt \n",
    "\n",
    "# Turn the output tokens into text\n",
    "output_text = tokenizer.decode(outputs[0])\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"RAG answer:\\n{output_text.replace(prompt, '')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0318ad72ace84708bab290f8c4c172a8": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_9c2da37efd1e45efb527af360b7e4b31",
        "IPY_MODEL_10602954695d4a55bc4afdc55c17da26",
        "IPY_MODEL_0b93cefba41f40ffa686d3da6d49db7b"
       ],
       "layout": "IPY_MODEL_c905790d2fca44b399a3c7202f0c2342"
      }
     },
     "06365a5fef0c40fd83edadbc571b435a": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "07008ea33ad94259abb7b80323d28c9e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "0917b4c992e046d5b5c8b65e200aafe4": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_ca34a67822ef49ad81c83c81cbce12fc"
      }
     },
     "0b352a6c01634fc9ad6cdce1dcdead30": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "0b93cefba41f40ffa686d3da6d49db7b": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_bca30987e1574d0392e5bc54c9066559"
      }
     },
     "0fa3ae8754f7482e9c1ed2dd9132ff61": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "10602954695d4a55bc4afdc55c17da26": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_7e14ba715844437aade8fb464f582ef0",
       "max": 4,
       "step": 0.1
      }
     },
     "116564f3f6d94cd187952c2905710c23": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_887fa4219f57449c829938623387d21a",
       "max": 4,
       "step": 0.1
      }
     },
     "1228ddbb649c4d1aa386786d3c41692d": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_26b879fe2c7443f0a8948a87b68a4206",
       "max": 4,
       "step": 0.1
      }
     },
     "17b43d90784e4d2db05a449af368a7cc": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "1858b407a99546e8831dcad68e43184e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_211ceb930bb346ba8163170fdba0d0b5"
      }
     },
     "1866cdbe14164ff59ad9fc7dc6cbf732": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "211ceb930bb346ba8163170fdba0d0b5": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "268d38e4e9c0436da48248eb5ecef53a": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_c86714643715443cb6c5ff5394055038",
       "value": "Loading checkpoint shards"
      }
     },
     "26b879fe2c7443f0a8948a87b68a4206": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "2888c46959964c91be12d8c65eb85893": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_d45b2fe2313448febcfd84932363a71c",
       "max": 4,
       "step": 0.1
      }
     },
     "32974282832f471f8e4ce2ab9655fa34": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_855b9baab5e544349026066b5e986fb4",
       "value": "Loading checkpoint shards"
      }
     },
     "3790bb6768ef4105983eba7aa0d0e178": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_4f71539242cc44b2a75c8e05c830df3c",
        "IPY_MODEL_116564f3f6d94cd187952c2905710c23",
        "IPY_MODEL_cad4c1670b2e4c8db0653efb39555871"
       ],
       "layout": "IPY_MODEL_1866cdbe14164ff59ad9fc7dc6cbf732"
      }
     },
     "405a5bc9aed84ab5a411d7c60cb869f5": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_d082ddab36de4f4eb0128b2c09ce2e39",
        "IPY_MODEL_84d6c522b3114d24841632552716e84f",
        "IPY_MODEL_47eb3db9d60e4dd5bb0a40e596036b23"
       ],
       "layout": "IPY_MODEL_a94d35229305450c8335555e39aa91c6"
      }
     },
     "45734edc58ea456bba6c0ed053d77151": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "47eb3db9d60e4dd5bb0a40e596036b23": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_ad923a70fe1c44ac9b16ccb1f56413da"
      }
     },
     "4f71539242cc44b2a75c8e05c830df3c": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_ebe8d30388a74e389f4ebb308bf5f570",
       "value": "Loading checkpoint shards"
      }
     },
     "4fea85eeca894336a82fa330b9037176": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "510af427059e4848a960afc3a87de234": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "5d2418a330ad4be69f6c4fa45abebf3b": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_06365a5fef0c40fd83edadbc571b435a",
       "max": 4,
       "step": 0.1
      }
     },
     "5d46bae21f0c4558a22a01379eedd12e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_0b352a6c01634fc9ad6cdce1dcdead30",
       "value": "Loading checkpoint shards"
      }
     },
     "63f39644c3c045bd91f3d2057d01e22e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_17b43d90784e4d2db05a449af368a7cc",
       "max": 4,
       "step": 0.1
      }
     },
     "67c7c24612634398bb97b3f970a3464d": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_f6feff281eba4037be520db53d3276a8",
       "value": "Loading checkpoint shards"
      }
     },
     "7016f01868424a5e8293cac3958a0b55": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_fb60c679a82749418c67d59aa5cee54e"
      }
     },
     "770505fb827d4f08a508c107d514cb50": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "77a6e9e82005485582c786044b824fc8": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "7e14ba715844437aade8fb464f582ef0": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "83a670e4ff65414788bd5f0e44ee392e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "84d6c522b3114d24841632552716e84f": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_0fa3ae8754f7482e9c1ed2dd9132ff61",
       "max": 4,
       "step": 0.1
      }
     },
     "855b9baab5e544349026066b5e986fb4": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "87611b6546cb480db5d5faddbe4463ff": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_32974282832f471f8e4ce2ab9655fa34",
        "IPY_MODEL_e249501ff7894ca1806a3e5f22669951",
        "IPY_MODEL_be7301c58c754268863c0a581fa4f839"
       ],
       "layout": "IPY_MODEL_510af427059e4848a960afc3a87de234"
      }
     },
     "887fa4219f57449c829938623387d21a": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "8c9349fb395749a09c4b0f77fa14b7cf": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "8f0169924ea4487188ae4b5b37e687fb": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "9a2371424da34ac68d18994704b68612": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_67c7c24612634398bb97b3f970a3464d",
        "IPY_MODEL_63f39644c3c045bd91f3d2057d01e22e",
        "IPY_MODEL_1858b407a99546e8831dcad68e43184e"
       ],
       "layout": "IPY_MODEL_8c9349fb395749a09c4b0f77fa14b7cf"
      }
     },
     "9c2da37efd1e45efb527af360b7e4b31": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_07008ea33ad94259abb7b80323d28c9e",
       "value": "Loading checkpoint shards"
      }
     },
     "a218e46988214664a2fb9d3dd9805836": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "a25879fc5b4e436ba7f2ceb48315e862": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "a40010cf9eb446ff9ee6c6f66e593707": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_a25879fc5b4e436ba7f2ceb48315e862",
       "value": "Loading checkpoint shards"
      }
     },
     "a560cbf1a9944b92a220196bfe8ac7b1": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_e3e88c35370c40a2b5d6355d9d097243",
        "IPY_MODEL_e2e4a346414c416fa8343b7893a10059",
        "IPY_MODEL_f514b69ba150471da3070b0a9497fdcd"
       ],
       "layout": "IPY_MODEL_da48575487ac4c4bbf6b4317e71ec51a"
      }
     },
     "a94d35229305450c8335555e39aa91c6": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "acc5b1172a1c4c4ea50d49ee4ac3be9d": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_268d38e4e9c0436da48248eb5ecef53a",
        "IPY_MODEL_2888c46959964c91be12d8c65eb85893",
        "IPY_MODEL_0917b4c992e046d5b5c8b65e200aafe4"
       ],
       "layout": "IPY_MODEL_d9ca6644cdf640afb8ca0ec3c903cd8c"
      }
     },
     "ad58276044ff460d81e610d38959981d": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_a40010cf9eb446ff9ee6c6f66e593707",
        "IPY_MODEL_5d2418a330ad4be69f6c4fa45abebf3b",
        "IPY_MODEL_c6d3696f39bd44a985a9ae816679bef1"
       ],
       "layout": "IPY_MODEL_770505fb827d4f08a508c107d514cb50"
      }
     },
     "ad923a70fe1c44ac9b16ccb1f56413da": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "b0704b395c0f41ebada54043433f37bc": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "bca30987e1574d0392e5bc54c9066559": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "be7301c58c754268863c0a581fa4f839": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_b0704b395c0f41ebada54043433f37bc"
      }
     },
     "c2dd15f1465740039af84f3b4091423a": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "c6d3696f39bd44a985a9ae816679bef1": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_d00e302e7d8a4b7fb9df1111edfd0269"
      }
     },
     "c86714643715443cb6c5ff5394055038": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "c905790d2fca44b399a3c7202f0c2342": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "ca34a67822ef49ad81c83c81cbce12fc": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "cad4c1670b2e4c8db0653efb39555871": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_c2dd15f1465740039af84f3b4091423a"
      }
     },
     "d00e302e7d8a4b7fb9df1111edfd0269": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "d082ddab36de4f4eb0128b2c09ce2e39": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_4fea85eeca894336a82fa330b9037176",
       "value": "Loading checkpoint shards"
      }
     },
     "d45b2fe2313448febcfd84932363a71c": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "d9ca6644cdf640afb8ca0ec3c903cd8c": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "da48575487ac4c4bbf6b4317e71ec51a": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "e249501ff7894ca1806a3e5f22669951": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_83a670e4ff65414788bd5f0e44ee392e",
       "max": 4,
       "step": 0.1
      }
     },
     "e2e4a346414c416fa8343b7893a10059": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "ProgressModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_8f0169924ea4487188ae4b5b37e687fb",
       "max": 4,
       "step": 0.1
      }
     },
     "e3e88c35370c40a2b5d6355d9d097243": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_45734edc58ea456bba6c0ed053d77151",
       "value": "Loading checkpoint shards"
      }
     },
     "ebe8d30388a74e389f4ebb308bf5f570": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "f514b69ba150471da3070b0a9497fdcd": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HTMLModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "layout": "IPY_MODEL_a218e46988214664a2fb9d3dd9805836"
      }
     },
     "f642cf8bca9c4f7582ec17e2667728fd": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "HBoxModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4",
       "children": [
        "IPY_MODEL_5d46bae21f0c4558a22a01379eedd12e",
        "IPY_MODEL_1228ddbb649c4d1aa386786d3c41692d",
        "IPY_MODEL_7016f01868424a5e8293cac3958a0b55"
       ],
       "layout": "IPY_MODEL_77a6e9e82005485582c786044b824fc8"
      }
     },
     "f6feff281eba4037be520db53d3276a8": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     },
     "fb60c679a82749418c67d59aa5cee54e": {
      "model_module": "jupyter-js-widgets",
      "model_module_version": "~2.1.4",
      "model_name": "LayoutModel",
      "state": {
       "_model_module_version": "~2.1.4",
       "_view_module_version": "~2.1.4"
      }
     }
    },
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
